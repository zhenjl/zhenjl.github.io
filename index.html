<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title> Zen 3.1 &middot; Zen 3.1 </title>

  
  <link rel="stylesheet" href="http://zhen.org/css/poole.css">
  <link rel="stylesheet" href="http://zhen.org/css/syntax.css">
  <link rel="stylesheet" href="http://zhen.org/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.ico">

  
  <link href="http://zhen.org/index.xml/" rel="alternate" type="application/rss+xml" title="Zen 3.1" />

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-681691-1', 'auto');
  ga('send', 'pageview');

</script>
</head>
<body>

<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1 class="brand"><a href="http://zhen.org">Zen 3.1</a></h1>
      <p class="lead">
       Product. Data. Code 
      </p>
    </div>



    <ul class="sidebar-nav">
      <li><a href="http://zhen.org/blog">Archive</a></li>
      
    </ul>
      <a href="https://twitter.com/zhenjl"><i class="fa fa-twitter-square"></i></a>&nbsp;&nbsp;
      
      
      <a href="https://github.com/zhenjl"><i class="fa fa-github-square"></i></a>&nbsp;&nbsp;
      

    <p class="footnote">Powered by <a href="http://hugo.spf13.com">Hugo</a> <br/>
    Theme originally made by <a href="http://twitter.com/mdo">@mdo</a> <br/>
    Theme modified by <a href="http://npf.io">Nate Finch</a> <br/>
    &copy; 2015 Jian Zhen. All rights reserved.</p>
    
  </div>
</div>

    <div class="content container">
<div class="posts">

  
  <div class="post">
    <h1 class="post-title">
      <a href="http://zhen.org/blog/sequence-high-performance-sequential-semantic-log--parser/">
        Sequence: A High Performance Sequential Semantic Log Parser at 175,000 MPS
      </a>
    </h1>

    <span class="post-date">Sun, Feb 1, 2015</span>

    

<p><a href="http://godoc.org/github.com/strace/sequence"><img src="http://godoc.org/github.com/strace/sequence?status.svg" alt="GoDoc" />
</a></p>

<p><a href="http://godoc.org/github.com/strace/sequence/sequence"><img src="http://godoc.org/github.com/strace/sequence/sequence?status.svg" alt="GoDoc" />
</a></p>

<p><a href="https://github.com/strace/sequence">github repo</a></p>

<p><code>sequence</code> is a <em>high performance sequential semantic log parser</em>.</p>

<ul>
<li>It is <em>sequential</em> because it goes through a log message sequentially and does not use regular expressions.</li>
<li>It is <em>semantic</em> because it tries to extract meaningful information out of the log messages and give them semantic indicators, e.g., src IPv4 or dst IPv4.</li>
<li>It is a <em>parser</em> because it will take a message and parses out the meaningful parts.</li>
<li>It is <em>high performance</em> because it can parse 100K+ messages per second without the need to separate parsing rules by log source type.</li>
</ul>

<p><strong><code>sequence</code> is currently under active development and should be considered unstable until further notice.</strong></p>

<h3 id="toc_0">Motivation</h3>

<p>Log messages are notoriusly difficult to parse because they all have different formats. Industries (see Splunk, ArcSight, Tibco LogLogic, Sumo Logic, Logentries, Loggly, LogRhythm, etc etc etc) have been built to solve the problems of parsing, understanding and analyzing log messages.</p>

<p>Let&rsquo;s say you have a bunch of log files you like to parse. The first problem you will typically run into is you have no way of telling how many DIFFERENT types of messages there are, so you have no idea how much work there will be to develop rules to parse all the messages. Not only that, you have hundreds of thousands, if not  millions of messages, in front of you, and you have no idea what messages are worth parsing, and what&rsquo;s not.</p>

<p>The typical workflow is develop a set of regular expressions and keeps testing against the logs until some magical moment where all the logs you want parsed are parsed. Ask anyone who does this for a living and they will tell you this process is long, frustrating and error-prone.</p>

<p>Even after you have developed a set of regular expressions that match the original set of messages, if new messages come in, you will have to determine which of the new messages need to be parsed. And if you develop a new set of regular expressions to parse those new messages, you still have no idea if the regular expressions will conflict with the ones you wrote before. If you write your regex parsers too liberally, it can easily parse the wrong messages.</p>

<p>After all that, you will end up finding out the regex parsers are quite slow. It can typically parse several thousands messages per second. Given enough CPU resources on a large enough machine, regex parsers can probably parse tens of thousands of messages per second. Even to achieve this type of performance, you will likely need to limit the number of regular expressions the parser has. The more regex rules, the slower the parser will go.</p>

<p>To work around this performance issue, companies have tried to separate the regex rules for different log message types into different parsers. For example, they will have a parser for Cisco ASA logs, a parser for sshd logs, a parser for Apache logs, etc etc. And then they will require the users to tell them which parser to use (usually by indicating the log source type of the originating IP address or host.)</p>

<p>Sequence is developed to make analyzing and parsing log messages a lot easier and faster.</p>

<h3 id="toc_1">Performance</h3>

<p>The following performance benchmarks are run on a single 4-core (2.8Ghz i7) MacBook Pro. The first file is a
bunch of sshd logs, averaging 98 bytes per message. The second is a Cisco ASA log file, averaging 180 bytes per message.</p>

<pre><code>  $ ./sequence bench -p ../../patterns/sshd.txt -i ../../data/sshd.all
  Parsed 212897 messages in 1.69 secs, ~ 126319.27 msgs/sec

  $ ./sequence bench -p ../../patterns/asa.txt -i ../../data/allasa.log
  Parsed 234815 messages in 2.89 secs, ~ 81323.41 msgs/sec

  $ ./sequence bench -d ../patterns -i ../data/asasshsudo.log
  Parsed 447745 messages in 4.47 secs, ~ 100159.65 msgs/sec
</code></pre>

<p>Performance can be improved by adding more cores:</p>

<pre><code>  GOMAXPROCS=2 ./sequence bench -p ../../patterns/sshd.txt -i ../../data/sshd.all -w 2
  Parsed 212897 messages in 1.00 secs, ~ 212711.83 msgs/sec

  $ GOMAXPROCS=2 ./sequence bench -p ../../patterns/asa.txt -i ../../data/allasa.log -w 2
  Parsed 234815 messages in 1.56 secs, ~ 150769.68 msgs/sec

  $ GOMAXPROCS=2 ./sequence bench -d ../patterns -i ../data/asasshsudo.log -w 2
  Parsed 447745 messages in 2.52 secs, ~ 177875.94 msgs/sec
</code></pre>

<h3 id="toc_2">Documentation</h3>

<p>Documentation is available at godoc: <a href="http://godoc.org/github.com/strace/sequence">package</a>, <a href="http://godoc.org/github.com/strace/sequence/sequence">command</a>.</p>

<h3 id="toc_3">License</h3>

<p>Copyright &copy; 2014 Dataence, LLC. All rights reserved.</p>

<p>Licensed under the Apache License, Version 2.0 (the &ldquo;License&rdquo;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>

<p><a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p>

<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &ldquo;AS IS&rdquo; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>

<h3 id="toc_4">Roadmap / Futures</h3>

<p>There are some pattern files developed for ASA, Sudo and SSH in the <code>patterns</code> directory. The goal is to continue to develop a set of patterns for the various log messages, and along the way add additional features to the parser that can help make it even easier to parse log messages. So currently there&rsquo;s not a set roadmap.</p>

<h2 id="toc_5">Concepts</h2>

<p>The following concepts are part of the package:</p>

<ul>
<li><p>A <em>Token</em> is a piece of information extracted from the original log message. It is a struct that contains fields for <em>TokenType</em>, <em>FieldType</em>, <em>Value</em>, and indicators of whether it&rsquo;s a key or value in the key=value pair.</p></li>

<li><p>A <em>TokenType</em> indicates whether the token is a literal string (one that does not change), a variable string (one that could have different values), an IPv4 or IPv6 address, a MAC address, an integer, a floating point number, or a timestamp.</p></li>

<li><p>A <em>FieldType</em> indicates the semantic meaning of the token. For example, a token could be a source IP address (%srcipv4%), or a user (%srcuser% or %dstuser%), an action (%action%) or a status (%status%).</p></li>

<li><p>A <em>Sequence</em> is a list of Tokens. It is returned by the <em>Tokenizer</em>, and the <em>Parser</em>.</p></li>

<li><p>A <em>Scanner</em> is a sequential lexical analyzer that breaks a log message into a sequence of tokens. It is sequential because it goes through log message sequentially tokentizing each part of the message, without the use of regular expressions. The scanner currently recognizes time stamps, IPv4 addresses, URLs, MAC addresses,
integers and floating point numbers. It also recgonizes key=value or key=&ldquo;value&rdquo; or key=&lsquo;value&rsquo; or key=<value> pairs.</p></li>

<li><p>A <em>Parser</em> is a tree-based parsing engine for log messages. It builds a parsing tree based on pattern sequence supplied, and for each message sequence, returns the matching pattern sequence. Each of the message tokens will be marked with the semantic field types.</p></li>
</ul>

<h2 id="toc_6">Sequence Command</h2>

<p>The <code>sequence</code> command is developed to demonstrate the use of this package. You can find it in the <code>sequence</code> directory. The <code>sequence</code> command implements the <em>sequential semantic log parser</em>.</p>

<pre><code>   Usage:
     sequence [command]

   Available Commands:
     scan                      scan will tokenize a log file or message and output a list of tokens
     parse                     parse will parse a log file and output a list of parsed tokens for each of the log messages
     bench                     benchmark the parsing of a log file, no output is provided
     help [command]            Help about any command
</code></pre>

<h3 id="toc_7">Scan</h3>

<pre><code>  Usage:
    sequence scan [flags]

   Available Flags:
    -h, --help=false: help for scan
    -m, --msg=&quot;&quot;: message to tokenize
</code></pre>

<p>Example</p>

<pre><code>  $ ./sequence scan -m &quot;jan 14 10:15:56 testserver sudo:    gonner : tty=pts/3 ; pwd=/home/gonner ; user=root ; command=/bin/su - ustream&quot;
  #   0: { Field=&quot;%funknown%&quot;, Type=&quot;%ts%&quot;, Value=&quot;jan 14 10:15:56&quot; }
  #   1: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;testserver&quot; }
  #   2: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;sudo&quot; }
  #   3: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;:&quot; }
  #   4: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;gonner&quot; }
  #   5: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;:&quot; }
  #   6: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;tty&quot; }
  #   7: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;=&quot; }
  #   8: { Field=&quot;%funknown%&quot;, Type=&quot;%string%&quot;, Value=&quot;pts/3&quot; }
  #   9: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;;&quot; }
  #  10: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;pwd&quot; }
  #  11: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;=&quot; }
  #  12: { Field=&quot;%funknown%&quot;, Type=&quot;%string%&quot;, Value=&quot;/home/gonner&quot; }
  #  13: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;;&quot; }
  #  14: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;user&quot; }
  #  15: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;=&quot; }
  #  16: { Field=&quot;%funknown%&quot;, Type=&quot;%string%&quot;, Value=&quot;root&quot; }
  #  17: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;;&quot; }
  #  18: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;command&quot; }
  #  19: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;=&quot; }
  #  20: { Field=&quot;%funknown%&quot;, Type=&quot;%string%&quot;, Value=&quot;/bin/su&quot; }
  #  21: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;-&quot; }
  #  22: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;ustream&quot; }
</code></pre>

<h3 id="toc_8">Parse</h3>

<pre><code>  Usage:
    sequence parse [flags]

   Available Flags:
    -h, --help=false: help for parse
    -i, --infile=&quot;&quot;: input file, required
    -o, --outfile=&quot;&quot;: output file, if empty, to stdout
    -d, --patdir=&quot;&quot;: pattern directory,, all files in directory will be used
    -p, --patfile=&quot;&quot;: initial pattern file, required
</code></pre>

<p>The following command parses a file based on existing rules. Note that the
performance number (9570.20 msgs/sec) is mostly due to reading/writing to disk.
To get a more realistic performance number, see the benchmark section below.</p>

<pre><code>  $ ./sequence parse -d ../../patterns -i ../../data/sshd.all  -o parsed.sshd
  Parsed 212897 messages in 22.25 secs, ~ 9570.20 msgs/sec
</code></pre>

<p>This is an entry from the output file:</p>

<pre><code>  Jan 15 19:39:26 jlz sshd[7778]: pam_unix(sshd:session): session opened for user jlz by (uid=0)
  #   0: { Field=&quot;%createtime%&quot;, Type=&quot;%ts%&quot;, Value=&quot;jan 15 19:39:26&quot; }
  #   1: { Field=&quot;%apphost%&quot;, Type=&quot;%string%&quot;, Value=&quot;jlz&quot; }
  #   2: { Field=&quot;%appname%&quot;, Type=&quot;%string%&quot;, Value=&quot;sshd&quot; }
  #   3: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;[&quot; }
  #   4: { Field=&quot;%sessionid%&quot;, Type=&quot;%integer%&quot;, Value=&quot;7778&quot; }
  #   5: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;]&quot; }
  #   6: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;:&quot; }
  #   7: { Field=&quot;%funknown%&quot;, Type=&quot;%string%&quot;, Value=&quot;pam_unix&quot; }
  #   8: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;(&quot; }
  #   9: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;sshd&quot; }
  #  10: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;:&quot; }
  #  11: { Field=&quot;%funknown%&quot;, Type=&quot;%string%&quot;, Value=&quot;session&quot; }
  #  12: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;)&quot; }
  #  13: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;:&quot; }
  #  14: { Field=&quot;%object%&quot;, Type=&quot;%string%&quot;, Value=&quot;session&quot; }
  #  15: { Field=&quot;%action%&quot;, Type=&quot;%string%&quot;, Value=&quot;opened&quot; }
  #  16: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;for&quot; }
  #  17: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;user&quot; }
  #  18: { Field=&quot;%dstuser%&quot;, Type=&quot;%string%&quot;, Value=&quot;jlz&quot; }
  #  19: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;by&quot; }
  #  20: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;(&quot; }
  #  21: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;uid&quot; }
  #  22: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;=&quot; }
  #  23: { Field=&quot;%funknown%&quot;, Type=&quot;%integer%&quot;, Value=&quot;0&quot; }
  #  24: { Field=&quot;%funknown%&quot;, Type=&quot;%literal%&quot;, Value=&quot;)&quot; }
</code></pre>

<h3 id="toc_9">Benchmark</h3>

<pre><code>  Usage:
    sequence bench [flags]

   Available Flags:
    -c, --cpuprofile=&quot;&quot;: CPU profile filename
    -h, --help=false: help for bench
    -i, --infile=&quot;&quot;: input file, required
    -d, --patdir=&quot;&quot;: pattern directory,, all files in directory will be used
    -p, --patfile=&quot;&quot;: pattern file, required
    -w, --workers=1: number of parsing workers
</code></pre>

<p>The following command will benchmark the parsing of two files. First file is a
bunch of sshd logs, averaging 98 bytes per message. The second is a Cisco ASA
log file, averaging 180 bytes per message.</p>

<pre><code>  $ ./sequence bench -p ../../patterns/sshd.txt -i ../../data/sshd.all
  Parsed 212897 messages in 1.69 secs, ~ 126319.27 msgs/sec

  $ ./sequence bench -p ../../patterns/asa.txt -i ../../data/allasa.log
  Parsed 234815 messages in 2.89 secs, ~ 81323.41 msgs/sec
</code></pre>

<p>Performance can be improved by adding more cores:</p>

<pre><code>  GOMAXPROCS=2 ./sequence bench -p ../../patterns/sshd.txt -i ../../data/sshd.all -w 2
  Parsed 212897 messages in 1.00 secs, ~ 212711.83 msgs/sec

  $ GOMAXPROCS=2 ./sequence bench -p ../../patterns/asa.txt -i ../../data/allasa.log -w 2
  Parsed 234815 messages in 1.56 secs, ~ 150769.68 msgs/sec
</code></pre>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://zhen.org/blog/generating-porter2-fsm-for-fun-and-performance/">
        Generating Porter2 FSM For Fun and Performance in Go
      </a>
    </h1>

    <span class="post-date">Wed, Jan 21, 2015</span>

    

<p><a href="http://godoc.org/github.com/surgebase/porter2"><img src="http://godoc.org/github.com/surgebase/porter2?status.svg" alt="GoDoc" />
</a></p>

<h2 id="toc_0">tl;dr</h2>

<ul>
<li>This post describes the <a href="https://github.com/surgebase/porter2">Porter2</a> package I implemented. It is written in Go (#golang).</li>
<li>By using a <a href="http://en.wikipedia.org/wiki/Finite-state_machine">finite-state-machine</a> approach to <a href="http://snowball.tartarus.org/algorithms/english/stemmer.html">Porter2</a> <a href="http://en.wikipedia.org/wiki/Stemming">stemming</a>, I was able to achieve 660% better performance compare to other Go implementations.</li>
<li>FSM-based approach is great for known/fixed data set, but obviously not workable if the data set changes at runtime.</li>
<li>Hand-coding FSM is a PITA!!! <a href="https://github.com/surgebase/porter2/tree/master/cmd/suffixfsm">Automate</a> if possible.</li>
</ul>

<h2 id="toc_1">Introduction</h2>

<p>In a personal project I am working on, I had the need to perform word stemming in two scenarios. First, I need to perform stemming for all the string literals in a LARGE corpus and then determine if the words are in a fixed set of literals. Second, I need to perform stemming for a subset of words in real-time, as messages stream in.</p>

<p>In the first case, performance is important but not critical; in the second case, performance is a huge factor.</p>

<h3 id="toc_2">Stemming</h3>

<p>To start, according to <a href="http://en.wikipedia.org/wiki/Stemming">wikipedia</a>:</p>

<blockquote>
<p>Stemming is the term used in linguistic morphology and information retrieval to describe the process for reducing inflected (or sometimes derived) words to their word stem, base or root form—generally a written word form.</p>
</blockquote>

<p>As a quick example, the words <em>fail</em>, <em>failed</em>, and <em>failing</em> all mean something has <em>failed</em>. By stemming these three words, I will get a single form which is <em>fail</em>. I can then just use <em>fail</em> going forward instead of having to compare all three forms all the time.</p>

<p>The <a href="http://tartarus.org/martin/PorterStemmer/def.txt">Porter</a> stemming algorithm is by far the most commonly used stemmer and also considered to be one of the most gentle stemmers. The Porter stemming algorithm (or ‘Porter stemmer’) works by removing the commoner morphological and inflexional endings from words in English. Its main use is as part of a term normalisation process that is usually done when setting up Information Retrieval systems. (<a href="http://tartarus.org/martin/PorterStemmer/">ref</a>)</p>

<p><a href="http://snowball.tartarus.org/algorithms/english/stemmer.html">Porter2</a> is universally considered to be an enhancement over the original Porter algorithm. Porter2 has an improved set of rules and it&rsquo;s widely used as well.</p>

<h2 id="toc_3">Implementation</h2>

<p>This package, <a href="https://github.com/surgebase/porter2">Porter2</a>, implements the Porter2 stemmer. It is written completely using finite state machines to perform suffix comparison, rather than the usual string-based or tree-based approaches. As a result, it is 660% faster compare to string comparison-based approach written in the same (Go) language.</p>

<p>This implementation has been successfully validated with the dataset from <a href="http://snowball.tartarus.org/algorithms/english/">http://snowball.tartarus.org/algorithms/english/</a>, so it should be in a usable state. If you encounter any issues, please feel free to <a href="https://github.com/surgebase/porter2/issues">open an issue</a>.</p>

<p>Usage is fairly simple:</p>

<pre><code>import &quot;github.com/surgebase/porter2&quot;

fmt.Println(porter2.Stem(&quot;seaweed&quot;)) // should get seawe
</code></pre>

<h3 id="toc_4">Performance</h3>

<p>This implementation by far has the highest performance of the various Go-based implementations, AFAICT. I tested a few of the implementations and the results are below.</p>

<table>
<thead>
<tr>
<th>Implementation</th>
<th>Time</th>
<th>Algorithm</th>
</tr>
</thead>

<tbody>
<tr>
<td><a href="https://github.com/surgebase/porter2">surgebase</a></td>
<td>319.009358ms</td>
<td>Porter2</td>
</tr>

<tr>
<td><a href="https://github.com/dchest/stemmer">dchest</a></td>
<td>2.106912401s</td>
<td>Porter2</td>
</tr>

<tr>
<td><a href="https://github.com/kljensen/snowball">kljensen</a></td>
<td>5.725917198s</td>
<td>Porter2</td>
</tr>
</tbody>
</table>

<p>To run the test again, you can run <a href="https://github.com/surgebase/porter2/tree/master/cmd/compare">compare.go</a> (<code>go run compare.go</code>).</p>

<h3 id="toc_5">State Machines</h3>

<p>Most of the implementations, like the ones in the table above, rely completely on suffix string comparison. Basically there&rsquo;s a list of suffixes, and the code will loop through the list to see if there&rsquo;s a match. Given most of the time you are looking for the longest match, so you order the list so the longest is the first one. So if you are luckly, the match will be early on the list. But regardless that&rsquo;s a huge performance hit.</p>

<p>This implementation is based completely on finite state machines to perform suffix comparison. You compare each chacter of the string starting at the last character going backwards. The state machines will determine what the longest suffix is.</p>

<p>As an example, let&rsquo;s look at the 3 suffixes from step0 of the porte2 algorithm. The goal, and it&rsquo;s the same for all the other steps, it&rsquo;s to find the longest matching suffix.</p>

<pre><code>'
's
's'
</code></pre>

<p>If you were to build a non-space-optimized <a href="http://en.wikipedia.org/wiki/Suffix_tree">suffix tree</a>, you would get this, where R is the root of the tree, and any node with * is designated as a final state:</p>

<pre><code>        R
       / \
      '*  s
     /     \
    s       '*
   /
  '*
</code></pre>

<p>This is a fairly easy tree to build, and we actually did that in the FSM generator we will talk about later. However, to build a working suffix tree in Go, we would need to use a <code>map[rune]*node</code> structure at each of the nodes. And then search the map for each rune we encounter.</p>

<p>To test the performance of using a switch statement vs using a map, I wrote a <a href="https://github.com/surgebase/porter2/tree/master/cmd/switchvsmap">quick test</a>:</p>

<pre><code>switch: 4.956523ms
   map: 10.016601ms
</code></pre>

<p>The test basically runs a switch statement and a map each for 1,000,000 times. So it seems like using a switch statement is faster than a map. Though I think the compiler basically builds a map for all the switch case statements.  (Maybe we should call this post <em>Microbenchmarking for fun and performance</em>?)</p>

<p>In any case, let&rsquo;s go with the switch approach. We basically need to unroll the suffix tree into a finite state machine.</p>

<pre><code>        R0
       / \
      '1* s2
     /     \
    s3      '4*
   /
  '5*
</code></pre>

<p>To do that, we need to assign a state number to each of the nodes in the suffix tree, and output each of the states and the transitions based on the rune encountered. The tree above is the same as the one before, but now has a state number assigned to each node.</p>

<h3 id="toc_6">Generator</h3>

<p>I actually started building all the porter2 FSMs manually with a completely different approach than what I am describing here. I won&rsquo;t go into details here but needless to say, it was disastrous. Not only was hand coding state machines extremely error-prone, the approach I was taking also had a lot of potential for bugs. It took me MANY HOURS to hand build those FSMs but at the end, I was happy to abandon all of them for the approach I am taking now.</p>

<p>To reduce errors and make updating the FSM easier, I wrote a quick tool called <a href="https://github.com/surgebase/porter2/tree/master/cmd/suffixfsm">suffixfsm</a> to generate the FSMs. The tool basically takes a list of suffixes, creates a suffix tree as described above, and unrolls the tree into a set of states using the <code>switch</code> statement.</p>

<p>It took me just a couple hours to write and debug the tool, and I was well on my way to fixing other bugs!</p>

<p>For example, running the command <code>go run suffixfsm.go step0.txt</code> generated the following code. This is a complete function for step0 of the porter2 algorithm. The only thing missing is what to do with each of the final states, which are in the last <code>switch</code> statement.</p>

<pre><code>var (
		l int = len(rs) // string length
		m int			// suffix length
		s int			// state
		f int			// end state of longgest suffix
		r rune			// current rune
	)

loop:
	for i := 0; i &lt; l; i++ {
		r = rs[l-i-1]

		switch s {
		case 0:
			switch r {
			case '\'':
				s = 1
				m = 1
				f = 1
				// ' - final
			case 's':
				s = 2
			default:
				break loop
			}
		case 1:
			switch r {
			case 's':
				s = 4
			default:
				break loop
			}
		case 2:
			switch r {
			case '\'':
				s = 3
				m = 2
				f = 3
				// 's - final
			default:
				break loop
			}
		case 4:
			switch r {
			case '\'':
				s = 5
				m = 3
				f = 5
				// 's' - final
			default:
				break loop
			}
		default:
			break loop
		}
	}

	switch f {
	case 1:
		// ' - final

	case 3:
		// 's - final

	case 5:
		// 's' - final

	}

	return rs
</code></pre>

<h2 id="toc_7">Finally</h2>

<p>This is a technique that can probably be applied to any fixed data set. The performance may vary based on the size of the state machine so test it with both maps and FSM to see what works best.</p>

<p>Happy Go&rsquo;ing!</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="http://zhen.org/blog/golang-from-a-non-programmers-perspective/">
        Go: From a Non-Programmer&#39;s Perspective
      </a>
    </h1>

    <span class="post-date">Tue, Jan 13, 2015</span>

    

<p><em>Warning: Long Post. Over 3900 words according to <code>wc</code>. So read at your own risk. :)</em></p>

<p><a href="https://golang.org/">Go</a> is a fairly recent programming language <a href="http://golang.org/doc/faq#history">created</a> by Robert Griesemer, Rob Pike and Ken Thompson of Google. It has risen in popularity over the the past few years, especially since Go 1.0 was released.</p>

<p>There are a ton of posts out there that talks about the pros and cons of Go, and why one would use it or not. In addition, there&rsquo;s a bunch of posts out there written by different developers coming from different perspectives, such as Python, Ruby, Node, Rust, etc, etc. Recently I even read a couple of Chinese blog posts on why Go is popular in China, and why some of the Chinese developers have abandoned Go, which are quite interesting as well.</p>

<p>This post is my perspective of Go, how I picked it up, and what I think of it after using it for a while. It is not a post about why Go is better or worse than other languages.</p>

<p>In short, I like Go. It&rsquo;s the first programming language I&rsquo;ve used in recent years that I can actually build some interesting projects, e.g., <a href="https://github.com/surge/surgemq">SurgeMQ</a> (<a href="/blog/surgemq-mqtt-message-queue-750k-mps/">detailed post</a>), in my limited spare time.</p>

<h2 id="toc_0">My Background</h2>

<p>I am not a programmer/developer. Not full-time, not part-time, not moonlight. I tell my colleagues and teams that &ldquo;I am not technical.&rdquo;</p>

<p>But I do have a technical background. I have a MSCS degree from way back when, and have spent the first 6-7 years of my career performing security audits and penetration tests, and building one of the world&rsquo;s largest managed security services (at least at the time).</p>

<p>My programming langauge progression, when I was technical, has been BASIC (high school), Pascal and C (college), Perl, PHP, Java, and Javascript (during my technical career). I can&rsquo;t claim to be an &ldquo;expert&rdquo; in any of these languages, but I consider myself quite proficient in each at the time I was using them.</p>

<p>I was also reasonably network and system savvy, in the sense that I can get myself in and around the Solaris and Linux (UN*X) systems pretty well, and understand the networking stack sufficiently. I consider myself fairly proficient with the various system commands and tools.</p>

<p>For the past 12 years, however, I have not been a developer, nor a systems guy, nor a networking guy. Instead, I have been running product management for various startups and large companies in the security and infrastructure space.</p>

<p>Since the career change, I&rsquo;ve not done any meaningful code development. I&rsquo;ve written a script here and there, but nothing that I would consider to be &ldquo;software.&rdquo; However, I&rsquo;ve managed engineering teams as part of my resonsibility, in addition to product management, to produce large scale software.</p>

<p>In the past 12 years, my most used IDE is called Microsoft Office. So, in short, I am probably semi-technical, and know just enough to be dangerous.</p>

<h3 id="toc_1">My History with Go</h3>

<p>In <sup>2011</sup>&frasl;<sub>2012</sub>, I had the responsibility of building a brand new engineering team (I was already running product management) at VMware to embark on a new strategic initiative. The nature of the product/service is not important now. However, at the time, because the team is brand new, we had some leeway in choosing a language for the project. VMware at the time was heavily Java, and specifically Spring given the <a href="http://www.vmware.com/company/news/releases/springsource">2009 acquisition of SpringSource</a>. While the new team had mostly Java experience, there was desire to choose something less bloated, and something that had good support for the emerging patterns of distributed software.</p>

<h4 id="toc_2">First Touch</h4>

<p>Some of the team members had experience with Scala, so that became an obvious option. I did some research on the web, and found some discussions of Go. At the time, Go hasn&rsquo;t reached 1.0 yet, but there was already a buzz around it. I looked on Amazon, and found <a href="http://www.amazon.com/gp/product/B0083RVAJW/ref=docs-os-doi_0">The Way to Go</a>, which was probably the only Go book around at the time. For $3 on the Kindle, it was well worth it. However, due to the nascent nature of Go (pre 1.0), it was not a comfortable choice so I didn&rsquo;t put that as an option. But this was my <strong>first touch of Go and it felt relatively painless</strong>.</p>

<p>At the end, the team chose Scala because of existing experience, and that in theory, people with Java experience should move fairly easily to Scala. We were the first team in VMware to use Scala and we were pretty excited about it.</p>

<p>However, to this date, I am still not sure we made the right decision to move to Scala (not that it&rsquo;s wrong either.) The learning curve I believe was higher than we originally anticipated. Many of the developers wrote Java code w/ Scala syntax. And hiring also became an issue. Basically every new developer that came onboard must be sent to Typesafe for training. It was simply not easy for most developers who came from a non-functional mindset to jump into a totally functional mindset. Lastly, the knowledge differences of new Scala developers and experienced ones made it more difficult for them to collaborate.</p>

<p>I also tried to read up Scala and at least understand the concept. I even tried to take the online course on Coursera offered by Martin Odersky. However, I just could not get my non-functional mind to wrap around the functional Scala. And since I really didn&rsquo;t need to code (nor the developers want me to), I gave up on learning Scala.</p>

<h4 id="toc_3">Second Touch</h4>

<p>In any case, fast forward 2 years to Q3 of 2013. I had since left VMware and joined my current company, <a href="http://jolata.com">Jolata</a>, to build a big data network analytics solutions for mobile carriers and high-frequency trading financial services firms. We are a small startup that&rsquo;s trying to do a ton of things. So even though I run products, I have to get my hands dirty often.</p>

<p>One of the things we had to do as a company is to build a repeatable demo environment. The goal is to have a prebuilt vagrant VM that we can run on our Macs, and we can demonstrate our product without connecting to the network. The requirement was that we had an interesting set of data in the database so we can walk through different scenarios.</p>

<p>The data set we needed was network flow data. And to make the UI look realistic, interesting and non-blocky, we wanted to generate noisy data so the UI looks like it&rsquo;s monitoring a real network. Because all of the developers are focused on feature development, I took on the task of building out the data set.</p>

<p>By now, Go has released v1.1 and on its way to 1.2. It was then I started seriously considering Go as a candidate for this project. To build a tool that can generate the data set, we needed two libraries. The first is a <a href="http://en.wikipedia.org/wiki/Perlin_noise">Perlin Noise</a> generator, and the second is <a href="https://code.google.com/p/cityhash/">Google&rsquo;s Cityhash</a>. Neither of these were available in Go (or not that I remember). I thought this would be a great opportunity to test out Go. The end results were my Go Learn Projects <a href="https://github.com/dataence/perlinnoise">#0 Perlin</a>, and <a href="https://github.com/dataence/cityhash">#1 Cityhash</a>.</p>

<p>Both of these projects were relatively simple since I didn&rsquo;t have to spend a lot of time figuring out HOW to write them. Perlin Noise has well-established C libraries and algorithms, and Cityhash was written in C so it was easy to translate to Go. However, these projects gave me a good feel of how Go works.</p>

<p>In the end, I wrote the data generator in Go (private repo) and got the first taste of goroutines. Again, <strong>this second touch with Go was also relatively painless</strong>. The only confusion I had at the time was the Go source tree structure. Trying to understand $GOROOT, $GOPATH and other Go environment variables were all new to me. This was also the first time in 10 years that I really spent time writing a piece of software, so I just considered the confusion as my inexperience.</p>

<h4 id="toc_4">Third Touch and Beyond</h4>

<p>Today, I no longer code at work as we have more developers now. Also, the Jolata product is mostly C/C++, Java and Node, so Go is also no longer in the mix. However, After getting a taste of Go in the first couple of Go projects, I&rsquo;ve since spent a tremendous amount of my limited personal spare time working with it.</p>

<p>I have since written various libraries for <a href="https://github.com/dataence/bitmap">bitmap compression</a>, <a href="https://github.com/dataence/encoding">integer compression</a>, <a href="https://github.com/dataence/bloom">bloom filters</a>, <a href="https://github.com/dataence/skiplist">skiplist</a>, and <a href="https://github.com/dataence">many others</a>. And I have <a href="http://zhen.org/blog/">blogged my journey</a> along the way as I learn. With these projects, I&rsquo;ve learned how to use the Go toolchain, how to write idiomatic Go, how to write tests with Go, and more importantly, how to optimize Go.</p>

<p>Interestingly, one of my most popular posts is <a href="http://zhen.org/blog/go-vs-java-decoding-billions-of-integers-per-second/">Go vs Java: Decoding Billions of Integers Per Second</a>. This tells me that a lot of Java developers are potentially looking to adopt Go.</p>

<p>All these have allowed me to learn Go enough to build a real project, <a href="https://github.com/surge/surgemq">SurgeMQ</a>. It is by far my most popular project and one that I expect to continue developing.</p>

<h2 id="toc_5">My Views on Go</h2>

<p>Go is not just a langauge, it also has a very active community around it. The views are based on my observation over the past 1.5 years of using Go. My Go environment is primary Sublime Text 3 with GoSublime plugin.</p>

<h3 id="toc_6">As a Language&hellip;</h3>

<p>I am not a language theorist, nor do I claim to be a language expert. In fact, prior to actually using Go, I&rsquo;ve barely heard of generics, communicating sequential processes, and other &ldquo;cool&rdquo; and &ldquo;advanced&rdquo; concepts. I&rsquo;ve heard of all the new cool programming languages such as Clojure and Rust, but have never looked at any of the code. So my view of Go is basically one of a developer n00b.</p>

<p>In a way, I consider that to be an advantage coming in to a new programming language, in that I have no preconceived notion of how things &ldquo;SHOULD&rdquo; be. I can learn the language and use the constructs as they were intended, and not have to question WHY it was designed that way because it&rsquo;s different than what I know.</p>

<p>Others may consider this to be a huge disadvantage, since I don&rsquo;t know any better. There maybe constructs in other languages that would make my work a lot easier, or make my code a lot simpler.</p>

<p>However, as long as the language doesn&rsquo;t slow me down, then I feel it&rsquo;s serving my needs.</p>

<h4 id="toc_7">Go is Simple</h4>

<p>As a language for a new deverloper, Go was very easy to pick up. Go&rsquo;s design is fairly simple and minimalistic. You can sit down and read through the <a href="https://golang.org/ref/spec">Language Specification</a> fairly quickly in an idle afternoon. I actually didn&rsquo;t find the language reference until later. My first touch of Go was by scanning through the book <em>The Way To Go</em>. Regardless, there&rsquo;s not a lot to the language so it&rsquo;s relatively easy for someone like myself to pick up the basics. (Btw, I&rsquo;ve also never gone through the <a href="https://tour.golang.org/">Go Tour</a>. I know it&rsquo;s highly recommended to all new Go developers. I just never did it.)</p>

<p>There are more advanced concepts in Go, such as interface, channel, and goroutine. Channel in general is a fairly straightforward concept. Most new programmers should be able to understand that quickly. You write stuff in, you read stuff out. It&rsquo;s that simple. From there, you can slowly expand on the concept as you <em>go</em> along by adding buffered channels, or ranging over channels, or checking if the read is ok, or using quit channels.</p>

<p>For anyone coming from a language with threads, goroutine is not a difficult concept to understand. It&rsquo;s basically a light-weight thread that can be executed concurrently. You can run any function as a goroutine.</p>

<p>The more difficult concept is interface. That&rsquo;s because it&rsquo;s a <strike>fairly new concept that doesn&rsquo;t really exist in</strike> concept that&rsquo;s fairly different than other languages. Once you understand what interfaces are, it&rsquo;s fairly easy to start using them. However, designing your own interfaces is a different story.</p>

<p>The one thing I&rsquo;ve seen most developers complain about Go is the lack of generics. Egon made a nice <a href="https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4">Summary of Go Generics Discussions</a> that you can read through. For me personally, I don&rsquo;t know any better. I have never used generics and I haven&rsquo;t found a situation where I strongly require it.</p>

<p>As a language a team, the simplicity of Go is <em>HUGE</em>. It allows develoeprs to quickly come up to speed and be productive in the shortest period of time. And in this case, time is literally money.</p>

<h4 id="toc_8">Go is Opinionated</h4>

<p>Go is opinionated in many ways. For example, probably one of the most frustrating thing about Go is how to structure the code directory. Unlike other languages where you can just create a directory and get started, Go wants you to put things in $GOPATH. It took a few readings of <a href="https://golang.org/doc/code.html">How to Write Go Code</a> for me to grasp what&rsquo;s going on, and it took even longer for me to really get the hang of code organization, and how Go imports packages (e.g., <code>go get</code>).</p>

<p>If I go back and look at my first internal project, I would probably cry because it&rsquo;s all organized in a non-idiomatic way. However, once I got the hang of how Go expects things to be organized, it no longer was a obstacle for me. <strong>Instead of fighting the way things should be organized in Go, I learned to <em>go</em> with the flow.</strong> At the end of the day, the $GOPATH organizational structure actually helps me track the different packages I import.</p>

<p>Another way Go is opinionated is code formatting. Go, and Go developers, expect that all Go programs are formatted with <a href="http://blog.golang.org/go-fmt-your-code"><code>go fmt</code></a>. A lot of developers hate it and some even listed it as a top reason for leaving Go. However, this is one of those things that you just have to learn to <em>go</em> with the flow. Personally I love it.</p>

<p>And as a team language it will save a ton of argument time. Again, time is money for a new team. When my new VMware team got started, we probably spent a good 30 person-hours debating code formatting. That&rsquo;s $2700 at a $180K fully-burdened rate. And that&rsquo;s not counting all the issues we will run into later trying to reformat code that&rsquo;s not properly formatted.</p>

<p>Go is also very opininated in terms of variable use and package import. If a variable is declared but not used, the Go compiler will complain. If a package is imported but not used, the Go compiler will complain. Personally, I like the compiler complaining about the unused variables. It keeps the code clean, and reduce the chance of unexpected bugs. I am less concerned about unused packages but have also learned to live with the compiler complains. I use <a href="https://github.com/bradfitz/goimports">goimports</a> in Sublime Text 3 to effectively and quickly take care of the import statements. In fact, in 99% of the cases I don&rsquo;t even need to type in the import statements myself.</p>

<h4 id="toc_9">Go is Safe</h4>

<p>Go is safe for a couple of reasons. For a new developer, Go does not make it easy for you to be lazy. For example, Go is a statically typed language, which means every variable must explicitly have a type associated with it. The Go compiler does infer types under certain situations, but regardless, there&rsquo;s a type for every variable. This may feel uncomfortable for developers coming from dynamic languages, but the benefit definitely outweighs the cost. I&rsquo;ve experience first hand, as a product person waiting for bugs to be fixed, how long it takes to troubleshoot problems in Node. Having static types gives you a feeling of &ldquo;correctness&rdquo; after you have written the code.</p>

<p>Another example of Go not allowing you to be lazy is that Go&rsquo;s error handling is through the return of <code>error</code> from functions. There has been a ton of discussions and debates on the merit of <code>error</code> vs exception handling so I won&rsquo;t go through it here. However, for a new programmer, it really requires your explicit attention to handle the errors. And I consider that to be a good thing as you know what to expect at each step of the program.</p>

<p>Making things explicit and making it harder for developers to be lazy are a couple of the reasons that make Go safe.</p>

<p>Another reason is that <a href="http://golang.org/doc/faq#garbage_collection">Go has a garbage collector</a>. This makes it different from C/C++ as it no longer require developers to perform memory management. The difficulty in memory management is the single biggest source of memory leaks in C/C++ programs. Having a GC removes that burden from developers and makes the overall program much safer. Having said that, there&rsquo;s much improvement to be made to the GC given its nascent state. And, as I learned over the past 1.5 years, to write high performance programs in Go today, developers need to make serious efforts to reduce GC pressure.</p>

<p>Again, as a team langauge, the safety aspect is very important. The team will likely end up spending much less time dealing with memory bugs and focus more on feature development.</p>

<h4 id="toc_10">Go is Powerful</h4>

<p>What makes Go powerful are its simplicity, its high performance, and advanced concepts such as channels, goroutines, interfaces, type composition, etc. We have discussed all of these in previous sections.</p>

<p>In addition to all that, one of the killer feature of Go is that all Go programs are statically compiled into a single binary. There&rsquo;s no shared libraries to worry about. There&rsquo;s no jar files to worry about. There&rsquo;s no packages to bundle. It&rsquo;s just a single binary. And that&rsquo;s an extremely powerful feature from the deployment and maintenance perspectives. To deploy a Go program, you just need to copy a single Go binary over. To update it, copy a single Go binary over.</p>

<p>In contrast, to deploy a Node.js application, you may end up downloading hundreds of little packages at deployment time. And you have to worry about whether all these packages are compatible. The Node community has obviously developed a lot of good tools to manage dependencies and version control. But still, every time I see a Node app get deployed on a new machine, and have to download literally hundreds of little packages, I die a little inside.</p>

<p>Also, if you deploy C/C++ programs and depend on shared libraries, now you have to worry about OS and shared library version compatibility issues.</p>

<p>Another powerful feature of Go is that you can mix C and assembly code with Go code in a single program. I haven&rsquo;t used this extensively, but in my attempt to <a href="http://zhen.org/blog/go-vs-java-decoding-billions-of-integers-per-second/">optimize</a> the <a href="https://github.com/dataence/encoding">integer compression</a> library, I added different C and assembly snippets to try to squeeze the last ounce of performance out of Go. It was fairly easy and straightforward to do.</p>

<p>One last thing, Go has a very large and complete standard library. It enables developers to do most, if not all, of their work quickly and efficiently. As the language matures and the community grows, there will be more and more 3rd party open source libraries one can leverage.</p>

<h3 id="toc_11">As a Community</h3>

<p>Today, Go has a very active community behind it. Specifically, the information sources I&rsquo;ve followed and gotten help from include <a href="https://botbot.me/freenode/go-nuts/">#go-nuts IRC</a>, <a href="http://www.reddit.com/r/golang/search?q=golang&amp;sort=new&amp;restrict_sr=on&amp;t=all">golang subreddit</a>, and obviously the <a href="https://groups.google.com/forum/#!forum/golang-nuts">golang-nuts mailing list</a>.</p>

<p>I spent quite a bit of time in IRC when I first started. I&rsquo;ve gotten help from quite a few people such as dsal, tv42, and others, and I am grateful for that. I am spending less time there now because of the limited time I have (remember, my day job is not development. :)</p>

<p>There&rsquo;s been some sentiments in the developer community that Go developers (gophers) are Google worshippers, don&rsquo;t accept any feedbacks on language changes, harsh to new comers who come from different languages,  difficult to ask questions because the sample code is not on play.golang.org, etc etc.</p>

<p>To be clear, I&rsquo;ve never really spent much time with the different language communites, even when I was technical. So I have nothing else to compare to. So I can only speak from a human interaction level.</p>

<p>I can see it from both perspectives. For example, developers coming from different language backgrounds sometimes have experience with a different way of doing things. When they want to perfrom the same tasks in Go, they ask the question by saying here&rsquo;s how I solved this problem in language X, how do I translate that to Go?</p>

<p>In some cases I&rsquo;ve definitely seen people responding by saying that&rsquo;s not how Go works and you are doing it wrong. That type of response can quickly create negative sentiment and kill the conversation.</p>

<p>Another type of response I&rsquo;ve seen is some developers telling the original poster (OP) that they are not asking questions the right way, and then promptly sending the OP a link to some web page on how to properly ask questions. Again, I can see how the OP can have a negative view on the matter.</p>

<p>I&rsquo;ve expereinced some of this myself. When I implemented a <a href="https://github.com/dataence/bloom">Bloom Filter</a> package last year, I did a bunch of performance tests and wrote a <a href="http://zhen.org/blog/benchmarking-bloom-filters-and-hash-functions-in-go/">blog post</a> about the it. As a newbie learning Go, I felt like I accomplished something and I was pretty happy with it. I posted the link to reddit, and the first comment I got was</p>

<blockquote>
<p>Downvoted because I dislike this pattern of learning a new language and then immediately publishing performance data about it, before you know how to write idiomatic or performant code in it.</p>
</blockquote>

<p><strong>Ouch!!</strong> As a new Go developer, this is not the response I expected. In the end though, the commenter also pointed out something that helped me improve the performance of the implementation. I was grateful for that. It was also then I realized how important it is to reduce the number of allocation in order to reduce the Go GC pressure.</p>

<p>In hindsight, the comment has a very valid point. I can understand why some developers would feel annoyed about benchmarks from people who have no idea on what they are doing. Regardless, being nice is not a bad thing. Saying things like &ldquo;WTF is wrong with you&rdquo; (not related to the bloom filter post) will only push new developers away.</p>

<p>I quickly got over the sting because I am just too old to care about what others think I should or should not do. I continued my learning process by writing and optimizing Go packages, and posting the results in my blog. In fact, the <a href="http://zhen.org/blog/go-vs-java-decoding-billions-of-integers-per-second/">Go vs Java: Decoding Billions of Integers Per Second</a> post has many of the optimization techniques I tried to increase the performance of Go programs.</p>

<p>Overall though, I felt I&rsquo;ve learned a ton from the Go community. People have generally been helpful and are willing to offer solutions to problems. I have nothing to compare to, but I feel that the positives of the Go community far outweighs any negatives.</p>

<h2 id="toc_12">Conclusion</h2>

<p>In conclusion, it has been a tremendous 1.5 years of working with Go, and seeing Go grow both as a language and as a community has been very rewarding.</p>

<p>My focus now, in my limited spare personal time, is to continue the development of <a href="https://github.com/surge/surgemq">SurgeMQ</a>, which is a high performance MQTT broker and client library that aims to be fully compliant with MQTT 3.1 and 3.1.1 specs.</p>

  </div>
  
</div>

<div class="posts">
  <h1 class="post-title">Archive</h1>
  <ul class="posts">
      
      <li><span><a href="http://zhen.org/blog/sequence-high-performance-sequential-semantic-log--parser/">Sequence: A High Performance Sequential Semantic Log Parser at 175,000 MPS</a> - <time class="pull-right post-list">Sun, Feb 1, 2015</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/generating-porter2-fsm-for-fun-and-performance/">Generating Porter2 FSM For Fun and Performance in Go</a> - <time class="pull-right post-list">Wed, Jan 21, 2015</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/golang-from-a-non-programmers-perspective/">Go: From a Non-Programmer&#39;s Perspective</a> - <time class="pull-right post-list">Tue, Jan 13, 2015</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/pingmq-a-surgemq-based-icmp-monitoring-tool/">PingMQ: A SurgeMQ-based ICMP Monitoring Tool</a> - <time class="pull-right post-list">Thu, Dec 25, 2014</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/surgemq-high-performance-mqtt-server-and-client-libraries-in-go/">SurgeMQ: High Performance MQTT Server and Client Libraries in Go</a> - <time class="pull-right post-list">Wed, Dec 24, 2014</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/surgemq-mqtt-message-queue-750k-mps/">SurgeMQ: MQTT Message Queue @ 750,000 MPS</a> - <time class="pull-right post-list">Thu, Dec 4, 2014</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/graceful-shutdown-of-go-net-dot-listeners/">Graceful Shutdown of Go net.Listeners</a> - <time class="pull-right post-list">Thu, Dec 12, 2013</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/ring-buffer-variable-length-low-latency-disruptor-style/">Ring Buffer - Variable-Length, Low-Latency, Lock-Free, Disruptor-Style</a> - <time class="pull-right post-list">Sat, Nov 30, 2013</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/go-vs-java-decoding-billions-of-integers-per-second/">Go vs Java: Decoding Billions of Integers Per Second</a> - <time class="pull-right post-list">Thu, Nov 14, 2013</h4></time></span></li>
      
      <li><span><a href="http://zhen.org/blog/improving-cityhash-performance-by-go-profiling/">Improving Cityhash Performance by Go Profiling</a> - <time class="pull-right post-list">Sun, Nov 10, 2013</h4></time></span></li>
      
  </ul>
</div>

</div>

  </body>

</html>
